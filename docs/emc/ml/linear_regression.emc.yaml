emc_version: "1.0"
emc_id: "EMC-ML-001"

identity:
  name: "Ordinary Least Squares Linear Regression"
  version: "1.0.0"
  authors:
    - name: "PAIML Engineering"
      affiliation: "Sovereign AI Stack"
  status: "production"

governing_equation:
  latex: "\\hat{\\beta} = (X^T X)^{-1} X^T y"
  plain_text: "β̂ = (X^T X)^{-1} X^T y"
  description: |
    Ordinary Least Squares (OLS) linear regression finds the coefficients
    that minimize the sum of squared residuals. Under the Gauss-Markov
    assumptions, OLS is the Best Linear Unbiased Estimator (BLUE).
  equation_type: "algebraic"
  variables:
    - symbol: "y"
      description: "Response vector (n × 1)"
      units: "varies"
      type: "dependent"
    - symbol: "X"
      description: "Design matrix (n × p)"
      units: "varies"
      type: "independent"
    - symbol: "β"
      description: "True coefficient vector (p × 1)"
      units: "varies"
      type: "parameter"
    - symbol: "β̂"
      description: "Estimated coefficient vector"
      units: "varies"
      type: "output"
    - symbol: "ε"
      description: "Error term (n × 1)"
      units: "varies"
      type: "noise"

analytical_derivation:
  primary_citation:
    authors: ["Gauss, C.F."]
    title: "Theoria Motus Corporum Coelestium"
    year: 1809
    publisher: "Perthes et Besser"
  supporting_citations:
    - authors: ["Hastie, T.", "Tibshirani, R.", "Friedman, J."]
      title: "The Elements of Statistical Learning"
      year: 2009
      publisher: "Springer"
      edition: "2nd"
  derivation_method: "Minimization of SSE"
  derivation_summary: |
    Model: y = Xβ + ε

    Minimize SSE = ||y - Xβ||² = (y - Xβ)^T(y - Xβ)

    Taking derivative and setting to zero:
    ∂SSE/∂β = -2X^T(y - Xβ) = 0
    X^T Xβ = X^T y
    β̂ = (X^T X)^{-1} X^T y

    Gauss-Markov: Under E[ε] = 0, Var[ε] = σ²I, and X full rank,
    OLS is BLUE (Best Linear Unbiased Estimator).

domain_of_validity:
  assumptions:
    - "Linearity: E[y|X] = Xβ"
    - "Full rank: X has rank p (no perfect multicollinearity)"
    - "Exogeneity: E[ε|X] = 0"
    - "Homoscedasticity: Var[ε|X] = σ²I (for efficient OLS)"
    - "No autocorrelation: Cov[ε_i, ε_j] = 0 for i ≠ j"
    - "For inference: ε ~ N(0, σ²I)"

analytical_solution:
  estimator: "β̂ = (X^T X)^{-1} X^T y"
  properties:
    - name: "Unbiasedness"
      value: "E[β̂] = β"
    - name: "Variance"
      value: "Var[β̂] = σ²(X^T X)^{-1}"
    - name: "Residual variance estimator"
      value: "s² = ||y - Xβ̂||² / (n - p)"
    - name: "R-squared"
      value: "R² = 1 - SSE/SST"
  test_cases:
    - name: "Simple regression"
      X: [[1, 1], [1, 2], [1, 3], [1, 4], [1, 5]]
      y: [2.1, 4.0, 5.9, 8.1, 9.8]
      expected_beta: [0.1, 2.0]
      tolerance: 0.1
    - name: "Perfect fit"
      X: [[1, 1], [1, 2], [1, 3]]
      y: [3, 5, 7]
      expected_beta: [1, 2]
      expected_r_squared: 1.0
      tolerance: 1.0e-10

verification_tests:
  tests:
    - id: "OLS-001"
      name: "Coefficient recovery"
      condition: "||β̂ - β_true|| < tolerance for synthetic data"
      tolerance: 0.01
    - id: "OLS-002"
      name: "Residual orthogonality"
      condition: "X^T(y - Xβ̂) ≈ 0"
      tolerance: 1.0e-10
    - id: "OLS-003"
      name: "Unbiasedness check"
      condition: "E[β̂] = β over many samples"
      tolerance: 0.05

falsification_criteria:
  criteria:
    - id: "OLS-FC-001"
      name: "Normal equation violation"
      condition: "X^T Xβ̂ ≠ X^T y"
      threshold: 1.0e-10
      severity: "critical"
    - id: "OLS-FC-002"
      name: "Biased estimator"
      condition: "|E[β̂] - β| > tolerance for large samples"
      threshold: 0.1
      severity: "major"
    - id: "OLS-FC-003"
      name: "R² out of bounds"
      condition: "R² < 0 or R² > 1"
      threshold: null
      severity: "critical"
